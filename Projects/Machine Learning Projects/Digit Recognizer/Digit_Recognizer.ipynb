{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Digit_Recognizer.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vU03u4w7yj-g"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.datasets import mnist \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from keras.models import load_model"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCl38vAeJs9H"
      },
      "source": [
        "def load_data():\n",
        "    #Loading the DataSet\n",
        "    (train_xs, train_ys), (test_xs, test_ys) = mnist.load_data()\n",
        "    #Checking the shape of the data\n",
        "    print(train_xs.shape)\n",
        "    print(test_xs.shape)\n",
        "    #Reshaping the train and test set to include grayscale colour channel\n",
        "    train_xs = train_xs.reshape(*train_xs.shape,1)\n",
        "    test_xs = test_xs.reshape(*test_xs.shape,1)\n",
        "    #Checking data type of the train and test sets \n",
        "    print(train_xs.dtype)\n",
        "    print(test_xs.dtype)\n",
        "    #Type casting to float\n",
        "    train_xs = train_xs.astype('float32')\n",
        "    test_xs = test_xs.astype('float32')\n",
        "    #Normalizing the values between 0 to 1\n",
        "    train_xs = train_xs/255\n",
        "    test_xs = test_xs/255\n",
        "    return (train_xs, train_ys), (test_xs,test_ys)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYlmihEEJ5_o"
      },
      "source": [
        "def create_model():\n",
        "  #Making a model\n",
        "    model = Sequential()\n",
        "    #Adding Convolutional Layer\n",
        "    model.add(Conv2D(input_shape = (28,28,1), kernel_size = 5, filters = 8, strides = 1, activation = 'relu', kernel_initializer = 'VarianceScaling'))\n",
        "    #Adding Pooling Layer \n",
        "    model.add(MaxPooling2D(pool_size= (2,2), strides = 2))\n",
        "    #Extracting more useful information\n",
        "    model.add(Conv2D(kernel_size = 5, filters = 16, strides = 1, activation = 'relu', kernel_initializer = 'VarianceScaling'))\n",
        "    #Flattening the output of the previous layer \n",
        "    model.add(Flatten())\n",
        "    #Adding the Fully Connected Layer\n",
        "    model.add(Dense(units = 128, activation = 'relu', kernel_initializer = 'VarianceScaling'))\n",
        "    #Softmax Activation\n",
        "    model.add(Dense(units = 10, activation = 'softmax', kernel_initializer = 'VarianceScaling'))\n",
        "    #Compiling the model and adding the optimizer, loss function and performance metric\n",
        "    model.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics= ['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6WKLST-KJ9SH"
      },
      "source": [
        "def train():\n",
        "    #Training the model\n",
        "    model.fit(train_xs, train_ys, batch_size = 32, validation_data = (test_xs, test_ys), epochs = 12, shuffle = True, verbose = 1)\n",
        "    #Checking Accuracy\n",
        "    test_loss, test_accuracy = model.evaluate(test_xs, test_ys, verbose = 0)\n",
        "    print('Test Loss  : ', test_loss)\n",
        "    print('Test Accuracy  :', test_accuracy)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C7AuhOQKCFDM",
        "outputId": "08fa634a-8023-4743-ecf9-66d98b502174"
      },
      "source": [
        "#Will run only if file is the entry point\n",
        "#Allows file to be imported without executing the code below\n",
        "if __name__ == '__main__' :\n",
        "    (train_xs,train_ys), (test_xs,test_ys) = load_data()\n",
        "    model = create_model()\n",
        "    model.summary()\n",
        "    train()\n",
        "\n",
        "    #Saving the model\n",
        "    model.save('model.h5')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "(60000, 28, 28)\n",
            "(10000, 28, 28)\n",
            "uint8\n",
            "uint8\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 24, 24, 8)         208       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 12, 12, 8)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 8, 8, 16)          3216      \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               131200    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 135,914\n",
            "Trainable params: 135,914\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/12\n",
            "1875/1875 [==============================] - 32s 17ms/step - loss: 0.1522 - accuracy: 0.9537 - val_loss: 0.0551 - val_accuracy: 0.9830\n",
            "Epoch 2/12\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0511 - accuracy: 0.9840 - val_loss: 0.0391 - val_accuracy: 0.9862\n",
            "Epoch 3/12\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0388 - accuracy: 0.9877 - val_loss: 0.0355 - val_accuracy: 0.9880\n",
            "Epoch 4/12\n",
            "1875/1875 [==============================] - 31s 17ms/step - loss: 0.0263 - accuracy: 0.9917 - val_loss: 0.0397 - val_accuracy: 0.9876\n",
            "Epoch 5/12\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0213 - accuracy: 0.9928 - val_loss: 0.0319 - val_accuracy: 0.9899\n",
            "Epoch 6/12\n",
            "1875/1875 [==============================] - 33s 17ms/step - loss: 0.0173 - accuracy: 0.9944 - val_loss: 0.0462 - val_accuracy: 0.9882\n",
            "Epoch 7/12\n",
            "1875/1875 [==============================] - 34s 18ms/step - loss: 0.0141 - accuracy: 0.9954 - val_loss: 0.0405 - val_accuracy: 0.9896\n",
            "Epoch 8/12\n",
            "1875/1875 [==============================] - 32s 17ms/step - loss: 0.0107 - accuracy: 0.9967 - val_loss: 0.0452 - val_accuracy: 0.9891\n",
            "Epoch 9/12\n",
            "1875/1875 [==============================] - 30s 16ms/step - loss: 0.0087 - accuracy: 0.9971 - val_loss: 0.0447 - val_accuracy: 0.9886\n",
            "Epoch 10/12\n",
            "1875/1875 [==============================] - 31s 17ms/step - loss: 0.0083 - accuracy: 0.9973 - val_loss: 0.0538 - val_accuracy: 0.9879\n",
            "Epoch 11/12\n",
            "1875/1875 [==============================] - 31s 17ms/step - loss: 0.0077 - accuracy: 0.9974 - val_loss: 0.0422 - val_accuracy: 0.9904\n",
            "Epoch 12/12\n",
            "1875/1875 [==============================] - 31s 17ms/step - loss: 0.0060 - accuracy: 0.9984 - val_loss: 0.0565 - val_accuracy: 0.9892\n",
            "Test Loss  :  0.05648967996239662\n",
            "Test Accuracy  : 0.9891999959945679\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}